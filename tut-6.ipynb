{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5800ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f026158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/16 12:18:08 WARN Utils: Your hostname, Udhhavs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.29.9 instead (on interface en0)\n",
      "22/05/16 12:18:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/16 12:18:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/16 12:18:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/16 12:18:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/05/16 12:18:20 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/05/16 12:18:20 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/05/16 12:18:20 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Udhhav\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/udhhav/Desktop/pyspark/LinkedIn/'\n",
    "file_path = data_path+\"utlization.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb170be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"json\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45d0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c5ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8c39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18719829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.42|03/05/2019 21:36:14|       0.49|      100|           61|\n",
      "|           0.46|03/05/2019 23:11:14|       0.37|      100|           42|\n",
      "|           0.35|03/05/2019 23:21:14|       0.64|      100|           38|\n",
      "|           0.35|03/06/2019 00:31:14|       0.56|      100|           51|\n",
      "|            0.6|03/07/2019 10:16:14|        0.5|      100|           63|\n",
      "|           0.43|03/07/2019 12:56:14|        0.4|      100|           55|\n",
      "|           0.32|03/07/2019 16:16:14|       0.52|      100|           63|\n",
      "|           0.38|03/07/2019 23:01:14|       0.43|      100|           70|\n",
      "|           0.29|03/07/2019 23:41:14|       0.36|      100|           56|\n",
      "|           0.27|03/08/2019 04:46:14|        0.5|      100|           52|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select distinct * from utilization limit 10\n",
    "\"\"\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16a634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|sid| sc|\n",
      "+---+---+\n",
      "|100| 47|\n",
      "|100| 43|\n",
      "|100| 62|\n",
      "|100| 50|\n",
      "|100| 43|\n",
      "|100| 48|\n",
      "|100| 58|\n",
      "|100| 58|\n",
      "|100| 62|\n",
      "|100| 45|\n",
      "|100| 47|\n",
      "|100| 60|\n",
      "|100| 57|\n",
      "|100| 44|\n",
      "|100| 47|\n",
      "|100| 66|\n",
      "|100| 65|\n",
      "|100| 66|\n",
      "|100| 42|\n",
      "|100| 63|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\n",
    "\"\"\"\n",
    "select server_id as sid, session_count as sc from utilization\n",
    "\n",
    "\"\"\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f653d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.66|03/05/2019 08:06:48|       0.31|      120|           54|\n",
      "|           0.58|03/05/2019 08:11:48|       0.38|      120|           64|\n",
      "|           0.55|03/05/2019 08:16:48|       0.61|      120|           54|\n",
      "|            0.7|03/05/2019 08:21:48|       0.35|      120|           80|\n",
      "|            0.6|03/05/2019 08:26:48|       0.39|      120|           71|\n",
      "|           0.53|03/05/2019 08:31:48|       0.35|      120|           49|\n",
      "|           0.73|03/05/2019 08:36:48|       0.42|      120|           73|\n",
      "|           0.41|03/05/2019 08:41:48|        0.6|      120|           72|\n",
      "|           0.62|03/05/2019 08:46:48|       0.57|      120|           57|\n",
      "|           0.67|03/05/2019 08:51:48|       0.44|      120|           78|\n",
      "|           0.67|03/05/2019 08:56:48|       0.38|      120|           73|\n",
      "|           0.39|03/05/2019 09:01:48|       0.47|      120|           58|\n",
      "|            0.5|03/05/2019 09:06:48|       0.29|      120|           78|\n",
      "|           0.38|03/05/2019 09:11:48|       0.38|      120|           56|\n",
      "|           0.53|03/05/2019 09:16:48|       0.38|      120|           47|\n",
      "|           0.74|03/05/2019 09:21:48|       0.25|      120|           69|\n",
      "|           0.53|03/05/2019 09:26:48|       0.57|      120|           73|\n",
      "|           0.54|03/05/2019 09:31:48|       0.64|      120|           65|\n",
      "|            0.7|03/05/2019 09:36:48|       0.52|      120|           55|\n",
      "|           0.54|03/05/2019 09:41:48|       0.27|      120|           74|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select * from utilization where server_id =120\n",
    "\"\"\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed45584e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c60b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, session_count from utilization where session_count > 70\n",
    "\"\"\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2d6333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239659"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce71ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2733\n",
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           71|\n",
      "|      120|           73|\n",
      "|      120|           72|\n",
      "|      120|           78|\n",
      "|      120|           73|\n",
      "|      120|           78|\n",
      "|      120|           73|\n",
      "|      120|           74|\n",
      "|      120|           78|\n",
      "|      120|           75|\n",
      "|      120|           75|\n",
      "|      120|           73|\n",
      "|      120|           79|\n",
      "|      120|           72|\n",
      "|      120|           77|\n",
      "|      120|           75|\n",
      "|      120|           72|\n",
      "|      120|           79|\n",
      "|      120|           75|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, session_count from utilization where session_count > 70\n",
    "and server_id = 120\n",
    "\"\"\")\n",
    "print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f49b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2733\n",
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, session_count from utilization where session_count > 70\n",
    "and server_id = 120\n",
    "order by session_count desc\n",
    "\"\"\")\n",
    "print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4257bd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      103|   10000|\n",
      "|      104|   10000|\n",
      "|      106|   10000|\n",
      "|      100|   10000|\n",
      "|      105|   10000|\n",
      "|      101|   10000|\n",
      "|      102|   10000|\n",
      "|      112|   10000|\n",
      "|      113|   10000|\n",
      "|      110|   10000|\n",
      "|      107|   10000|\n",
      "|      111|   10000|\n",
      "|      108|   10000|\n",
      "|      109|   10000|\n",
      "|      119|   10000|\n",
      "|      116|   10000|\n",
      "|      114|   10000|\n",
      "|      115|   10000|\n",
      "|      120|   10000|\n",
      "|      118|   10000|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, count(*)\n",
    "from utilization\n",
    "group by server_id\n",
    "\"\"\")\n",
    "print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1422726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      120|   10000|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, count(*)\n",
    "from utilization\n",
    "group by server_id\n",
    "having server_id = 120\n",
    "\"\"\")\n",
    "# print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a547d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      103|    8744|\n",
      "|      104|    7366|\n",
      "|      100|     391|\n",
      "|      105|    1110|\n",
      "|      101|    9808|\n",
      "|      102|    8586|\n",
      "|      112|    7425|\n",
      "|      113|    9418|\n",
      "|      110|    2826|\n",
      "|      107|    5646|\n",
      "|      111|    3093|\n",
      "|      108|    8375|\n",
      "|      109|    3129|\n",
      "|      116|    1167|\n",
      "|      114|    2128|\n",
      "|      115|    5284|\n",
      "|      120|    2733|\n",
      "|      118|    7913|\n",
      "|      117|    3605|\n",
      "|      126|    6365|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, count(*)\n",
    "from utilization\n",
    "where session_count > 70\n",
    "group by server_id\n",
    "\"\"\")\n",
    "# print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "167bdb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      101|    9808|\n",
      "|      113|    9418|\n",
      "|      145|    9304|\n",
      "|      103|    8744|\n",
      "|      102|    8586|\n",
      "|      133|    8583|\n",
      "|      108|    8375|\n",
      "|      149|    8288|\n",
      "|      137|    8248|\n",
      "|      148|    8027|\n",
      "|      123|    7918|\n",
      "|      118|    7913|\n",
      "|      112|    7425|\n",
      "|      139|    7383|\n",
      "|      104|    7366|\n",
      "|      121|    7084|\n",
      "|      142|    7084|\n",
      "|      146|    7072|\n",
      "|      126|    6365|\n",
      "|      144|    6220|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, count(*)\n",
    "from utilization\n",
    "where session_count > 70\n",
    "group by server_id\n",
    "order by 2 desc\n",
    "\"\"\")\n",
    "# print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb1928f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------+------------------+\n",
      "|server_id|min(session_count)|round(avg(session_count), 2)|max(session_count)|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "|      149|                71|                       84.96|                99|\n",
      "|      148|                71|                        84.7|                99|\n",
      "|      147|                71|                       73.74|                77|\n",
      "|      146|                71|                       82.95|                95|\n",
      "|      145|                71|                       86.98|               103|\n",
      "|      144|                71|                       81.38|                92|\n",
      "|      143|                71|                        71.0|                71|\n",
      "|      142|                71|                        82.9|                95|\n",
      "|      141|                71|                       76.05|                82|\n",
      "|      140|                71|                       81.29|                92|\n",
      "|      139|                71|                       83.33|                96|\n",
      "|      137|                71|                       85.01|                99|\n",
      "|      136|                71|                       77.96|                85|\n",
      "|      135|                71|                       73.43|                76|\n",
      "|      134|                71|                       74.22|                78|\n",
      "|      133|                71|                       85.47|               100|\n",
      "|      132|                71|                       74.02|                78|\n",
      "|      131|                71|                       78.43|                87|\n",
      "|      130|                71|                       75.51|                80|\n",
      "|      129|                71|                       76.17|                82|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "select server_id, min(session_count),round(avg(session_count),2),max(session_count)\n",
    "from utilization\n",
    "where session_count > 70\n",
    "group by server_id\n",
    "order by 1 desc\n",
    "\"\"\")\n",
    "# print(df_sql.count())\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2d5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
